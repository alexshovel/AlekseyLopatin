{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221acc63"
      },
      "source": [
        "### Установка зависимостей\n"
      ],
      "id": "221acc63"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc3a1b2f",
        "outputId": "434b13d5-46a6-4897-f30b-9c29ff2cf0e5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.7).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install xvfb\n",
        "!pip install gym[atari] autorom[accept-rom-license] gymnasium[mujoco] stable-baselines3 PyVirtualDisplay --quiet"
      ],
      "id": "fc3a1b2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffkBKqzCrQHM"
      },
      "outputs": [],
      "source": [
        "!pip install -q swig\n",
        "!pip install -q gymnasium"
      ],
      "id": "ffkBKqzCrQHM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry-zx4D-tTrg"
      },
      "outputs": [],
      "source": [
        "!pip install -q 'shimmy>=0.2.1'"
      ],
      "id": "Ry-zx4D-tTrg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0fa5004"
      },
      "source": [],
      "id": "f0fa5004"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd3628a3"
      },
      "outputs": [],
      "source": [
        "# Импорт необходимых пакетов\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import DQN"
      ],
      "id": "bd3628a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8e2713d"
      },
      "source": [
        "### Выбор среды\n",
        "Давайте определим задачу, которую мы будем решать, используя алгоритм Q-learning и библиотеки gym и stable-baselines3.\n"
      ],
      "id": "c8e2713d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8677e9b6"
      },
      "source": [
        "#### Создание среды Taxi-v3\n",
        "\n",
        "Мы используем метод gym.make() для создания среды с именем 'LunarLander-v2'."
      ],
      "id": "8677e9b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Zc5F8H8tFsD"
      },
      "outputs": [],
      "source": [
        "ENV_NAME = \"Taxi-v3\"\n",
        "TIMESTEPS = 400_000"
      ],
      "id": "6Zc5F8H8tFsD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1f793a3"
      },
      "outputs": [],
      "source": [
        "\n",
        "env = gym.make(ENV_NAME)"
      ],
      "id": "a1f793a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eac4a7d4"
      },
      "source": [
        "#### Описание задачи\n",
        "Мы сохраняем информацию о пространстве наблюдений (observation_space) и пространстве действий (action_space). observation_space представляет собой пространство всех возможных состояний в задаче, а action_space - пространство всех возможных действий, которые агент может предпринять."
      ],
      "id": "eac4a7d4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d230741c"
      },
      "outputs": [],
      "source": [
        "# Описание задачи\n",
        "observation_space = env.observation_space\n",
        "action_space = env.action_space"
      ],
      "id": "d230741c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae44f0f7"
      },
      "source": [
        "Эти шаги предварительно готовят нас к использованию выбранной среды для обучения и тестирования агента с использованием алгоритма Q-learning."
      ],
      "id": "ae44f0f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f744ee93"
      },
      "source": [
        "### Решение задачи\n",
        "На этом шаге мы используем алгоритм Q-learning, представленный в stable-baselines3, для решения задачи CartPole. Давайте разберем каждый этап.\n"
      ],
      "id": "f744ee93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "131bbf9c"
      },
      "source": [
        "#### Инициализация модели DQN\n",
        "Мы создаем экземпляр модели Deep Q-Network (DQN) с использованием DQN(\"MlpPolicy\", env, verbose=1). Здесь \"MlpPolicy\" означает полносвязную нейронную сеть в качестве политики. env - это среда CartPole, а verbose=1 добавляет вывод для отслеживания прогресса обучения."
      ],
      "id": "131bbf9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4725ebc2",
        "outputId": "40fe437e-31ac-428c-887f-7f6f955a11e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "# Инициализация модели DQN\n",
        "model = DQN(\"MlpPolicy\", env, verbose=1)"
      ],
      "id": "4725ebc2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc3bfd0a"
      },
      "source": [
        "#### Обучение модели\n",
        "Мы вызываем метод learn() для обучения модели на 400000 временных шагах (total_timesteps=400000)."
      ],
      "id": "cc3bfd0a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e2a56c9",
        "outputId": "d0cc2606-0a7d-4386-bc10-43c198f0bb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -227     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1000     |\n",
            "|    fps              | 832      |\n",
            "|    time_elapsed     | 239      |\n",
            "|    total_timesteps  | 199141   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000512 |\n",
            "|    n_updates        | 37285    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 200      |\n",
            "|    ep_rew_mean      | -224     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2000     |\n",
            "|    fps              | 745      |\n",
            "|    time_elapsed     | 535      |\n",
            "|    total_timesteps  | 399141   |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000276 |\n",
            "|    n_updates        | 87285    |\n",
            "----------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7ca0fc7c9de0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Обучение модели\n",
        "model.learn(total_timesteps=TIMESTEPS, log_interval=1000)\n",
        "model.save(\"dqn_lopatin_lr1\" )"
      ],
      "id": "6e2a56c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a16960"
      },
      "source": [
        "#### Тестирование модели\n",
        "Мы тестируем обученную модель, используя цикл, в котором агент принимает решения в соответствии с обученной политикой на каждом временном шаге. Мы используем метод render(), чтобы визуализировать среду в реальном времени."
      ],
      "id": "76a16960"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEeXdUbIJ35I"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "matplotlib.rcParams['animation.embed_limit'] = 2**128"
      ],
      "id": "PEeXdUbIJ35I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2f29060",
        "outputId": "13db1811-fc32-48ca-bfb2-80b5202c29da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|██████████| 1000/1000 [00:23<00:00, 42.43it/s]\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from tqdm import tqdm\n",
        "from IPython import display\n",
        "from pyvirtualdisplay import Display\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "\n",
        "\n",
        "d = Display()\n",
        "d.start()\n",
        "\n",
        "env = gym.make(ENV_NAME)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "img = []\n",
        "for _ in tqdm(range(1000)):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, terminated, truncated = env.step(int(action))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    img.append(env.render('rgb_array'))\n",
        "\n",
        "dpi = 72\n",
        "interval = 50 # ms\n",
        "\n",
        "plt.figure(figsize=(img[0].shape[1]/dpi,img[0].shape[0]/dpi),dpi=dpi)\n",
        "patch = plt.imshow(img[0])\n",
        "plt.axis=('off')\n",
        "animate = lambda i: patch.set_data(img[i])\n",
        "ani = animation.FuncAnimation(plt.gcf(),animate,frames=len(img),interval=interval)\n",
        "display.display(display.HTML(ani.to_jshtml()))\n"
      ],
      "id": "c2f29060"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57c178e6"
      },
      "source": [
        "#### Закрытие среды после тестирования\n",
        "По завершении тестирования мы закрываем среду с помощью env.close()."
      ],
      "id": "57c178e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "912717a1"
      },
      "outputs": [],
      "source": [
        "# Закрытие среды после тестирования\n",
        "env.close()"
      ],
      "id": "912717a1"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}