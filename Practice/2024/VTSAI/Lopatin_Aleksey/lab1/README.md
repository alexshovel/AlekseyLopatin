# Лабораторная работа 1

Студент гр. 4216 Лопатин Алексей


### Окружение Taxi-V3
Окружение представляет собой сетку 5x5 с четырмя обозначенными места посадки и высадки (красное, зеленое, желтое и синее). Такси трогается со случайной площади, а пассажир - в одном из назначенных мест.

Цель состоит в том, чтобы переместить такси к месту нахождения пассажира, забрать пассажира, добраться до желаемого пункта назначения и высадить пассажира. Как только пассажира высадят, эпизод заканчивается.

Игрок получает положительные награды за успешную высадку пассажира в нужном месте. Отрицательные вознаграждения за неправильные попытки посадить/высадить пассажира и за каждый шаг, на котором не получено очередное вознаграждение.

```
+---------+
|R: | : :G|
| : | : : |
| : : : : |
| | : | : |
|Y| : |B: |
+---------+
```

### Пространство наблюдений
Агент имеет дело с одним из 500 состояний и предпринимает следующие действия..

* 25 позиций автомобиля
* 5 состояний пассажира (в одной из 4 клеток или в такси)
* 4 пункта назначения


### Пространство действий
Пространство действий представлено следующими состояниями:

* 0: Переместиться назад
* 1: Переместиться вперед
* 2: Переместиться вправо
* 3: Переместиться влево
* 4: Подобрать пассажира
* 5: Высадить пассажира

### Система наград
* +20: Пассажир высажен в точке назначения
* -20: Пассажир высажен в неправильной точке или предпринято действие "взять пассажира" там, где пассажира нет
* -1: в случае любой другой ситуации

### Выполнение работы
Работа выполнена в системе google-collab. [Ссылка на notebook](https://github.com/alexshovel/AlekseyLopatin/blob/lopatin-lab1/Practice/2024/VTSAI/Lopatin_Aleksey/lab1/Lopatin_LR1.ipynb)

### Вывод
В ходе работы было произведено создание окружения Taxi, после чего на этом окружении было проведено обучение алгоритма Deep Q-Learning. По итогам визуализации действий обученного алгоритма видно, что модель обучилась только не совершать действия, приводящие к большому штрафу. При этом полезные действия не совершаются, а средняя награда отрицательная из-за большой продолжительности эпизода, когда модель повторяет однотипные действия. Это означает, что требуется либо настройка параметров алгоритма, либо использование другой архитектуры.